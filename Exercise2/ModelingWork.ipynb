{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "import datetime\n",
    "from calendar import isleap\n",
    "import missingno as msno\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, FactorAnalysis, TruncatedSVD, NMF, FastICA\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFromModel, VarianceThreshold\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pd.get_dummies(df, prefix=['channelName', 'title', 'sessionType', 'sessionSubType', 'genre', 'subGenre',\\n                                'episodeTitle', 'seriesTitle', 'gender'],\\n               columns=['channelName', 'title', 'sessionType', 'sessionSubType', 'genre', 'subGenre',\\n                                'episodeTitle', 'seriesTitle', 'gender'], sparse=True)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read transformed dataframe\n",
    "df = joblib.load('J:/Source/Exercises/Exercise2/ModelingData.pkl')\n",
    "\n",
    "# Under normal circumstances the first step I would undertake on the transformed data would be to encode\n",
    "# Encoding can be done either through sklearn's one hot encoding, or through pandas get_dummies, as below:\n",
    "'''pd.get_dummies(df, prefix=['channelName', 'title', 'sessionType', 'sessionSubType', 'genre', 'subGenre',\n",
    "                                'episodeTitle', 'seriesTitle', 'gender'],\n",
    "               columns=['channelName', 'title', 'sessionType', 'sessionSubType', 'genre', 'subGenre',\n",
    "                                'episodeTitle', 'seriesTitle', 'gender'], sparse=True)'''\n",
    "# Unfortunately, even while using sparse matrices, the memory requirements exceed my current machine's capabilities\n",
    "\n",
    "\n",
    "#Due to hardware limitations, we need to come up with alternative solutions\n",
    "#We still need to aggregate categorical labels per household, but first let's reduce the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove sessions with a 0 or negative length\n",
    "df = df.loc[df['sessionLength'] > 0]\n",
    "#Remove surf, due to our previous assumption that it is not actually a person watching a title\n",
    "df = df.loc[df['title'] != 'Surf']\n",
    "#Only look at normal playback speed\n",
    "df = df.loc[df['playbackSpeed'] == 1000]\n",
    "#Remove sessions with broadcast length < 0\n",
    "df = df.loc[df['broadcastLength'] > 0]\n",
    "#Do not consider sessions shorter than 15 seconds\n",
    "df = df.loc[df['sessionLength'] >= 15]\n",
    "\n",
    "#While there are concerns with removing the above pieces of information, we approach encoding again.\n",
    "#Unfortunately, our machine can still not handle the amount of data\n",
    "#Thus, we have 2 options:\n",
    "#1 - we resort to sampling procedures\n",
    "#2 - we create metrics based off of medians, quartiles, averages, etc. for each household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#We decide to move forward with the sampling procedure\n",
    "#First we only select the data that has a target\n",
    "dfTrain = df.loc[df['ageBinTarget'] != 'nan']\n",
    "\n",
    "#Delete households with less than 10 views\n",
    "counts = dfTrain['ID'].value_counts()\n",
    "dfTrain = dfTrain[df['ID'].isin(counts[counts >= 10].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve top 10 shows for each household\n",
    "store = pd.DataFrame()\n",
    "grouped = dfTrain.groupby('ID')\n",
    "for name, group in grouped:\n",
    "    temp = group.title.value_counts().iloc[:5].reset_index()\n",
    "    topTitles = temp.T.iloc[0, :]\n",
    "    topTitlesCount = temp.T.iloc[1, :]\n",
    "    combined = topTitlesCount.append(topTitles).reset_index(drop=True)\n",
    "    combined.rename(name, inplace=True)\n",
    "    store = store.append(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing encoding on a 15% sample at this point still does not manage to provide results due to spec limits\n",
    "#Delete some more columns:\n",
    "del dfTrain['sessionSubType']\n",
    "del dfTrain['subGenre']\n",
    "del dfTrain['episodeTitle']\n",
    "del dfTrain['seriesTitle']\n",
    "del dfTrain['title']\n",
    "del dfTrain['playbackSpeed']\n",
    "del dfTrain['broadcastLength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removal of all the columns make the sampling procedure irrelevant, hence we 'sample' all the data\n",
    "sample = dfTrain.sample(frac=1, random_state=333)\n",
    "dummySample = pd.get_dummies(sample, prefix=['sessionStartHour', 'sessionStartDayOfWeek', 'sessionEndHour',\n",
    "                                             'sessionEndDayOfWeek','broadcastStartHour', 'broadcastStartDay',\n",
    "                                             'broadcastEndHour', 'broadcastEndDay', 'channelName',\n",
    "                                             'sessionType', 'genre', 'gender'],\n",
    "               columns=['sessionStartHour', 'sessionStartDayOfWeek', 'sessionEndHour',\n",
    "                                             'sessionEndDayOfWeek','broadcastStartHour', 'broadcastStartDay',\n",
    "                                             'broadcastEndHour', 'broadcastEndDay', 'channelName',\n",
    "                                             'sessionType', 'genre', 'gender'], sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Groupby household and sum or average columns\n",
    "df = dummySample.groupby(['ID', 'ageBinTarget']).sum()\n",
    "temp = dummySample[['ID', 'sessionLength', 'viewingDifference']].groupby('ID').mean()\n",
    "del df['sessionLength']\n",
    "del df['viewingDifference']\n",
    "df['sessionLength'] = temp['sessionLength']\n",
    "df['viewingDifference'] = temp['viewingDifference']\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add top 5 titles and encode\n",
    "df = df.merge(store, left_on='ID', right_index=True)\n",
    "df = pd.get_dummies(df, prefix=[5, 6, 7, 8, 9], columns=[5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataframe into features and target\n",
    "y = df.iloc[:, 1]  # .as_matrix()\n",
    "X = df.iloc[:, 2:]  # .as_matrix()\n",
    "\n",
    "# Scalings\n",
    "sc = StandardScaler()\n",
    "ma = MaxAbsScaler()\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# Apply scaler\n",
    "colNames = X.columns\n",
    "X.fillna(0, inplace=True)\n",
    "X = sc.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove features with less than 5% variance\n",
    "colNames = X.columns\n",
    "sel = VarianceThreshold(threshold=0.16)\n",
    "X = sel.fit_transform(X)\n",
    "# Get column names back\n",
    "newCols = []\n",
    "for remain, col in zip(sel.get_support(), colNames):\n",
    "    if remain == True:\n",
    "        newCols.append(col)\n",
    "X = pd.DataFrame(X, columns=newCols)\n",
    "#X = transformed.merge(X.iloc[:, -5:], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform univariate feature selection (ANOVA F-values)\n",
    "colNames = X.columns\n",
    "selection_Percent = SelectPercentile(percentile=5)\n",
    "X = selection_Percent.fit_transform(X, y)\n",
    "# Get column names back\n",
    "newCols = []\n",
    "for remain, col in zip(selection_Percent.get_support(), colNames):\n",
    "    if remain == True:\n",
    "        newCols.append(col)\n",
    "X = pd.DataFrame(X, columns=newCols)\n",
    "#X = transformed.merge(X.iloc[:, -5:], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform tree-based feature selection\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "colNames = X.columns\n",
    "sel = SelectFromModel(clf, prefit=True)\n",
    "X = sel.transform(X)\n",
    "newCols = []\n",
    "for remain, col in zip(sel.get_support(), colNames):\n",
    "    if remain == True:\n",
    "        newCols.append(col)\n",
    "X = pd.DataFrame(X, columns=newCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testClassifier(clf):\n",
    "    param_grid = [{'n_estimators': range(50, 100, 10),\n",
    "                   'min_samples_split': range(10, 16, 1),\n",
    "                   'min_samples_leaf': range(5, 30, 5),\n",
    "                   'max_leaf_nodes': (5, 30, 5)\n",
    "                   }]\n",
    "\n",
    "    grid = GridSearchCV(clf, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "    fitted_classifier = grid.fit(X_train, y_train)\n",
    "    print(grid.best_score_, grid.best_params_)\n",
    "    predictions = fitted_classifier.predict(X_train)\n",
    "\n",
    "    fitted = clf.fit(X_train, y_train)\n",
    "    scoresCV = cross_val_score(clf, X_train, y_train, cv=3, verbose=0, n_jobs=-1)\n",
    "    trainPredictionsCV = cross_val_predict(clf, X_train, y_train, cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "    trainPredictions = clf.predict(X_train)\n",
    "    testPredictions = clf.predict(X_test)\n",
    "\n",
    "    score1 = metrics.accuracy_score(y_test, testPredictions)\n",
    "    score2 = metrics.cohen_kappa_score(y_test, testPredictions)\n",
    "    #score3 = metrics.roc_auc_score(y_test, testPredictions)\n",
    "    score4 = metrics.confusion_matrix(y_test, testPredictions)\n",
    "    score5 = metrics.classification_report(y_test, testPredictions)\n",
    "    print('Train score: ', metrics.accuracy_score(y_train, trainPredictions))\n",
    "    print('CV score: ', scoresCV)\n",
    "    print('Accuracy, Cohen Kappa')#, ROC AUC Score')\n",
    "    print(score1, score2)#, score3)\n",
    "    print('Confusion Matrix')\n",
    "    print(score4)\n",
    "    print('Classification Report')\n",
    "    print(score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 450 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed:   37.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.440124416796 {'max_leaf_nodes': 5, 'min_samples_leaf': 5, 'min_samples_split': 15, 'n_estimators': 80}\n",
      "Train score:  0.46500777605\n",
      "CV score:  [ 0.40930233  0.44392523  0.36448598]\n",
      "Accuracy, Cohen Kappa\n",
      "0.410094637224 0.159639920612\n",
      "Confusion Matrix\n",
      "[[70 30  9  0  0]\n",
      " [52 39 10  0  0]\n",
      " [17 13 21  0  0]\n",
      " [10 11 17  0  0]\n",
      " [ 5  4  9  0  0]]\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   (25, 35]       0.45      0.64      0.53       109\n",
      "   (35, 45]       0.40      0.39      0.39       101\n",
      "   (45, 55]       0.32      0.41      0.36        51\n",
      "   (55, 65]       0.00      0.00      0.00        38\n",
      "  (65, 115]       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.34      0.41      0.37       317\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 0.005)\n",
    "sgd = SGDClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(max_features='sqrt', max_depth=2)\n",
    "\n",
    "#print('LR')\n",
    "#testClassifier(lr)\n",
    "#print('DT')\n",
    "#testClassifier(dt)\n",
    "#print('RF')\n",
    "testClassifier(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
